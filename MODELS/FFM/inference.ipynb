{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFMLayer(nn.Module):\n",
    "    def __init__(self, field_dims, factor_dim):\n",
    "        '''\n",
    "        Parameter\n",
    "            field_dims: List of field dimensions \n",
    "                        The sum become the entire dimension of input (in sparse feature)\n",
    "                        The length become the number of fields\n",
    "            factor_dim: Factorization dimension\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.num_fields = len(field_dims)\n",
    "        self.input_dim = sum(field_dims) #.to(device)\n",
    "        self.embedding = nn.ModuleList([\n",
    "            # FILL HERE : Fill in the places `None` with                                      #\n",
    "            #             either `factorization_dim`, `self.num_fields`, or `self.input_dim`. #\n",
    "            nn.Embedding(\n",
    "                self.input_dim, factor_dim\n",
    "            ) for _ in range(self.num_fields)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Parameter\n",
    "            x: Long tensor of size \"(batch_size, num_fields)\"\n",
    "               Each value of variable is an index calculated including the dimensions up to the previous variable.\n",
    "               for instance, [gender:male, age:20, is_student:True] \n",
    "                             -> [1,0, 0,1,0,0,0,0, 0,1] in one-hot encoding\n",
    "                             -> x = [0,3,9].\n",
    "        Return\n",
    "            y: Float tensor of size \"(batch_size)\"\n",
    "        '''\n",
    "        \n",
    "        xv = [self.embedding[f](x) for f in range(self.num_fields)]\n",
    "        \n",
    "        y = list()\n",
    "        for f in range(self.num_fields):\n",
    "            for g in range(f + 1, self.num_fields):\n",
    "                y.append(xv[f][:, g] *  xv[g][:, f])\n",
    "        y = torch.stack(y, dim=1)\n",
    "        \n",
    "        return torch.sum(y, dim=(2,1))\n",
    "\n",
    "class FieldAwareFM(nn.Module):\n",
    "    def __init__(self, field_dims, factor_dim):\n",
    "        '''\n",
    "        Parameter\n",
    "            field_dims: List of field dimensions\n",
    "            factor_dim: Factorization dimension\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.input_dim = sum(field_dims)\n",
    "        self.encoding_dims = np.concatenate([[0], np.cumsum(field_dims)[:-1]])\n",
    "        self.linear = nn.Linear(self.input_dim, 1, bias=True) # FILL HERE : Fill in the places `None` #\n",
    "        self.ffm = FFMLayer(field_dims, factor_dim) # FILL HERE : Fill in the places `None` #\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Embedding):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "            elif isinstance(m, FFMLayer):\n",
    "                nn.init.normal_(m.v, 0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Parameter\n",
    "            x: Long tensor of size \"(batch_size, num_fields)\"\n",
    "                x_multihot: Multi-hot coding of x. size \"(batch_size, self.input_dim)\"\n",
    "        \n",
    "        Return\n",
    "            y: Float tensor of size \"(batch_size)\"\n",
    "        '''\n",
    "        dims = torch.tensor(self.input_dim).to(device)\n",
    "        x = x + x.new_tensor(self.encoding_dims).unsqueeze(0)\n",
    "        x_multihot = torch.zeros(x.size(0), dims).to(device).scatter_(1, x, 1.)\n",
    "        \n",
    "        y = self.linear(x_multihot).squeeze(1) + self.ffm(x) # FILL HERE : Use `self.linear()` and `self.ffm()` #\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users : 31360\n",
      "items : 6807\n"
     ]
    }
   ],
   "source": [
    "inference_df = pd.read_csv(\"inference_base.csv\")\n",
    "\n",
    "# load data\n",
    "with open('user_dict.pickle', 'rb') as fr:\n",
    "    user_dict = pickle.load(fr)\n",
    "\n",
    "# load data\n",
    "with open('item_dict.pickle', 'rb') as fr:\n",
    "    item_dict = pickle.load(fr)\n",
    "print(\"users :\", len(user_dict)) #31360\n",
    "print(\"items :\", len(item_dict)) #6807\n",
    "\n",
    "inference_df.sort_values(by=\"user\",axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/opt/ml/input/level2-movie-recommendation-level2-recsys-07/MODELS/FFM/inference.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B27.96.135.202/opt/ml/input/level2-movie-recommendation-level2-recsys-07/MODELS/FFM/inference.ipynb#ch0000021vscode-remote?line=0'>1</a>\u001b[0m a \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(user_dict\u001b[39m.\u001b[39mvalues())\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B27.96.135.202/opt/ml/input/level2-movie-recommendation-level2-recsys-07/MODELS/FFM/inference.ipynb#ch0000021vscode-remote?line=1'>2</a>\u001b[0m \u001b[39massert\u001b[39;00m a[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "a = list(user_dict.values())\n",
    "assert a[0] == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/opt/ml/input/level2-movie-recommendation-level2-recsys-07/MODELS/FFM/inference.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B27.96.135.202/opt/ml/input/level2-movie-recommendation-level2-recsys-07/MODELS/FFM/inference.ipynb#ch0000010vscode-remote?line=0'>1</a>\u001b[0m \u001b[39m# cuda setting\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B27.96.135.202/opt/ml/input/level2-movie-recommendation-level2-recsys-07/MODELS/FFM/inference.ipynb#ch0000010vscode-remote?line=1'>2</a>\u001b[0m use_cuda \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B27.96.135.202/opt/ml/input/level2-movie-recommendation-level2-recsys-07/MODELS/FFM/inference.ipynb#ch0000010vscode-remote?line=2'>3</a>\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m use_cuda \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B27.96.135.202/opt/ml/input/level2-movie-recommendation-level2-recsys-07/MODELS/FFM/inference.ipynb#ch0000010vscode-remote?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# cuda setting\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "batch_size = 1024\n",
    "\n",
    "inference_dataset = TensorDataset(torch.LongTensor(np.array(inference_df)))\n",
    "inference_dataloader = DataLoader(inference_dataset,\n",
    "                                  batch_size=batch_size,\n",
    "                                  pin_memory=use_cuda,\n",
    "                                  drop_last=False,\n",
    "                                  shuffle=False,\n",
    "                                  num_workers = 4,\n",
    "                                  )\n",
    "\n",
    "print(\"dataset length :\", len(inference_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(f\"FFM.pth\").to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_list = list()\n",
    "score_list = list()\n",
    "item_list = list()\n",
    "\n",
    "with torch.no_grad():\n",
    "    cnt = 0\n",
    "    for batch in tqdm(inference_dataloader):\n",
    "        x = batch[0].to(device) \n",
    "        # print (\"[DEBUG] model input x-----\")\n",
    "        \n",
    "        # print (\"--------------------------\")\n",
    "        output = model(x) #[B] ///x 에 대한 점수\n",
    "        #idx = torch.where(output >= 1)[0] # 점수가 1 이상인 index\n",
    "        \n",
    "        info = x.cpu()\n",
    "        #scores = output.index_select(0,idx).cpu().tolist()\n",
    "        scores = output.cpu().tolist()\n",
    "        users = info[:,0].tolist()\n",
    "        items = info[:,1].tolist()\n",
    "\n",
    "        user_list += users\n",
    "        item_list += items\n",
    "        score_list += scores\n",
    "\n",
    "np_user_list = np.array(user_list)\n",
    "np_item_list = np.array(item_list)\n",
    "np_score_list = np.array(score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 10 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = list()\n",
    "items = list()\n",
    "for key, user_code in tqdm(user_dict.items()):\n",
    "    u_code = int(user_code)\n",
    "\n",
    "    idx = np.where(np_user_list == u_code)[0].tolist()\n",
    "    \n",
    "    item_score = np_score_list.take(idx) #user code 에 해당하는 item_score\n",
    "    item_ = np_item_list.take(idx) # user code에 해당하는 item\n",
    "    top10_idx = np.argpartition(item_score, -10)[-10:] # 상위 10개 index 추출\n",
    "\n",
    "    top10_item = [int(item_dict[code]) for code in item_.take(top10_idx)] #top 10(item code -> item id)\n",
    "    user_id = [user_dict[u_code]] * 10\n",
    "\n",
    "    users += user_id\n",
    "    items += top10_item\n",
    "\n",
    "result = np.vstack((users,items)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### submission 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = pd.DataFrame(result, columns=['user','item'])\n",
    "info.to_csv(\"FFM_submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall@10 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "print(\"testing recall@10...\")\n",
    "# 학습에 사용된 user만 uniq_user에 저장\n",
    "uniq_user = list(user_dict.values())\n",
    "print (f\"Number of users : {len(uniq_user)}\")\n",
    "\n",
    "with open(\"/opt/ml/input/workspace/BERT4Rec/data/answers.json\", \"r\") as json_file: #answer.json 경로 지정\n",
    "    answer = json.load(json_file)\n",
    "\n",
    "# movielens-20m과 submission을 비교하여 Recall@10 값 계산\n",
    "submission_df = pd.read_csv(f\"submission.csv\")\n",
    "recall_result = []\n",
    "\n",
    "# 각 유저마다 recall@10 계산하여 list에 저장\n",
    "for user in tqdm(uniq_user):\n",
    "    submission_by_user = submission_df[submission_df['user'] == user]['item']\n",
    "\n",
    "    hit = 0\n",
    "    for item in submission_by_user:\n",
    "        if item in answer[str(user)]:\n",
    "            hit += 1\n",
    "\n",
    "        recall_result.append(hit / 10)\n",
    "\n",
    "# 전체 유저의 Recall@10의 평균 출력\n",
    "print (f\"Predicted submission result of Recall@10 = {np.average(recall_result)}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
