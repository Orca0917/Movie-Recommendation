{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle \n",
    "import torch\n",
    "from model import BERT4Rec\n",
    "import os\n",
    "from utils import *\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_N='' # 실험하고싶은 experiment number를 입력하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available() :\n",
    "    cuda_aval = True\n",
    "device = torch.device(\"cuda\" if cuda_aval else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_user_movie_interaction.csv 파일이 이미 존재합니다\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile('./data/new_user_movie_interaction.csv'):\n",
    "    print(\"new_user_movie_interaction.csv 파일이 이미 존재합니다\")\n",
    "else:\n",
    "    print(\"Start to make new_user_movie_interaction.csv (13minutes)\")\n",
    "    make_new_user_movie_interaction()\n",
    "    print(\"new_user_movie_interaction.csv 생성 완료\")\n",
    "uim = pd.read_csv(\"./data/new_user_movie_interaction.csv\")\n",
    "user_id = uim[\"user\"].to_numpy()\n",
    "\n",
    "with open(\"./data/input_data.pickle\", \"rb\") as fr : #user_seen_dict #preprocess.py에서 만들어짐\n",
    "    raw_data = pickle.load(fr)\n",
    "\n",
    "unique_sid = pd.read_csv(\"/opt/ml/input/data/train/pro_sg/unique_sid.txt\", header=None)\n",
    "show2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n",
    "\n",
    "item_id = unique_sid.to_numpy().reshape(6807)\n",
    "item_id = np.insert(item_id, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERT4Rec(\n",
       "  (item_emb): Embedding(6809, 60, padding_idx=0)\n",
       "  (pos_emb): Embedding(50, 60)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (emb_layernorm): LayerNorm((60,), eps=1e-06, elementwise_affine=True)\n",
       "  (blocks): ModuleList(\n",
       "    (0): BERT4RecBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_Q): Linear(in_features=60, out_features=60, bias=False)\n",
       "        (W_K): Linear(in_features=60, out_features=60, bias=False)\n",
       "        (W_V): Linear(in_features=60, out_features=60, bias=False)\n",
       "        (W_O): Linear(in_features=60, out_features=60, bias=False)\n",
       "        (attention): ScaledDotProductAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layerNorm): LayerNorm((60,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "      (pointwise_feedforward): PositionwiseFeedForward(\n",
       "        (W_1): Linear(in_features=60, out_features=240, bias=True)\n",
       "        (W_2): Linear(in_features=240, out_features=60, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layerNorm): LayerNorm((60,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BERT4RecBlock(\n",
       "      (attention): MultiHeadAttention(\n",
       "        (W_Q): Linear(in_features=60, out_features=60, bias=False)\n",
       "        (W_K): Linear(in_features=60, out_features=60, bias=False)\n",
       "        (W_V): Linear(in_features=60, out_features=60, bias=False)\n",
       "        (W_O): Linear(in_features=60, out_features=60, bias=False)\n",
       "        (attention): ScaledDotProductAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layerNorm): LayerNorm((60,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "      (pointwise_feedforward): PositionwiseFeedForward(\n",
       "        (W_1): Linear(in_features=60, out_features=240, bias=True)\n",
       "        (W_2): Linear(in_features=240, out_features=60, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layerNorm): LayerNorm((60,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out): Linear(in_features=60, out_features=6808, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(f\"./exp/experiment{EXP_N}/best.pth\").to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_split': 'split_by_user', 'dropout_rate': 0.1, 'epochs': 2, 'eta_min': 0.0001, 'hidden_units': 60, 'lr': 0.001, 'lr_decay_step': 30, 'mask_prob': 0.15, 'max_seq_len': 50, 'name': 'experiment', 'num_heads': 1, 'num_layer': 2, 'patience': 10, 'seed': 42, 'tmax': 200, 'train_batch_size': 64, 'train_rating_path': '/opt/ml/input/data/train/train_ratings.csv', 'val_ratio': 0.2, 'valid_batch_size': 1024}\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "with open(f'./exp/experiment{EXP_N}/config.yaml') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/31360 complete\n",
      "10000/31360 complete\n",
      "15000/31360 complete\n",
      "20000/31360 complete\n",
      "25000/31360 complete\n",
      "30000/31360 complete\n"
     ]
    }
   ],
   "source": [
    "max_len = config['max_seq_len']\n",
    "final = list()\n",
    "cnt = 0\n",
    "for key in raw_data.keys() :\n",
    "\n",
    "    length = len(raw_data[key])\n",
    "    if length < max_len : \n",
    "        dif = max_len-length\n",
    "        data = [0]*dif + raw_data[key][-length:]\n",
    "    else :\n",
    "        data = raw_data[key][-max_len:]\n",
    "\n",
    "    data = torch.LongTensor(data).unsqueeze(dim=0)\n",
    "    result = model(data)[0]\n",
    "    #t = result.detach().cpu().sum(axis=0)\n",
    "    t = result[0].detach().cpu()\n",
    "    t[data] = -np.inf\n",
    "    top_k_idx = np.argpartition(t, -10)[-10:]\n",
    "    rec_item_id = item_id[top_k_idx]\n",
    "    user = user_id[key]\n",
    "\n",
    "\n",
    "    for item in rec_item_id :\n",
    "        final.append((user, item))\n",
    "\n",
    "    cnt+=1\n",
    "\n",
    "    if cnt%5000 == 0 :\n",
    "        print(f\"{cnt}/31360 complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Done!\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir('./output'):\n",
    "    os.makedirs('./output')\n",
    "\n",
    "info = pd.DataFrame(final, columns=['user','item'])\n",
    "info.to_csv(f\"./output/submission_B4R_{EXP_N}.csv\",index=False)\n",
    "print(\"Inference Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
