{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load\n",
    "- inference_df : inference할 데이터셋 경로 설정\n",
    "- user_dict.pickle, item_dict.pickle 을 로드해서 category_code 형태로 되어있는 값 복구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users : 31360\n",
      "items : 6807\n"
     ]
    }
   ],
   "source": [
    "inference_df = pd.read_csv(\"inference_base.csv\") \n",
    "\n",
    "# load data\n",
    "with open('user_dict.pickle', 'rb') as fr:\n",
    "    user_dict = pickle.load(fr)\n",
    "\n",
    "# load data\n",
    "with open('item_dict.pickle', 'rb') as fr:\n",
    "    item_dict = pickle.load(fr)\n",
    "print(\"users :\", len(user_dict)) #31360\n",
    "print(\"items :\", len(item_dict)) #6807\n",
    "\n",
    "inference_df.sort_values(by=\"user\",axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "dataset length : 63988\n"
     ]
    }
   ],
   "source": [
    "# cuda setting\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "inference_dataset = TensorDataset(torch.LongTensor(np.array(inference_df)))\n",
    "inference_dataloader = DataLoader(inference_dataset,\n",
    "                                  batch_size=batch_size,\n",
    "                                  pin_memory=use_cuda,\n",
    "                                  drop_last=False,\n",
    "                                  shuffle=False,\n",
    "                                  num_workers = 4,\n",
    "                                  )\n",
    "\n",
    "print(\"dataset length :\", len(inference_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model load\n",
    "- 저장한 Model Load -> 경로 변경!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FieldAwareFM(\n",
       "  (linear): Linear(in_features=40230, out_features=1, bias=True)\n",
       "  (ffm): FFMLayer(\n",
       "    (embedding): ModuleList(\n",
       "      (0): Embedding(40230, 8)\n",
       "      (1): Embedding(40230, 8)\n",
       "      (2): Embedding(40230, 8)\n",
       "      (3): Embedding(40230, 8)\n",
       "      (4): Embedding(40230, 8)\n",
       "      (5): Embedding(40230, 8)\n",
       "      (6): Embedding(40230, 8)\n",
       "      (7): Embedding(40230, 8)\n",
       "      (8): Embedding(40230, 8)\n",
       "      (9): Embedding(40230, 8)\n",
       "      (10): Embedding(40230, 8)\n",
       "      (11): Embedding(40230, 8)\n",
       "      (12): Embedding(40230, 8)\n",
       "      (13): Embedding(40230, 8)\n",
       "      (14): Embedding(40230, 8)\n",
       "      (15): Embedding(40230, 8)\n",
       "      (16): Embedding(40230, 8)\n",
       "      (17): Embedding(40230, 8)\n",
       "      (18): Embedding(40230, 8)\n",
       "      (19): Embedding(40230, 8)\n",
       "      (20): Embedding(40230, 8)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(f\"./output/FFM3_2epoch.pth\").to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63988/63988 [07:36<00:00, 140.07it/s]\n"
     ]
    }
   ],
   "source": [
    "user_list = list()\n",
    "score_list = list()\n",
    "item_list = list()\n",
    "\n",
    "with torch.no_grad():\n",
    "    cnt = 0\n",
    "    for batch in tqdm(inference_dataloader):\n",
    "        x = batch[0].to(device) \n",
    "        output = model(x) #[B] ///x 에 대한 점수\n",
    "        #idx = torch.where(output >= 1)[0] # 점수가 1 이상인 index\n",
    "        \n",
    "        info = x.cpu()\n",
    "        #scores = output.index_select(0,idx).cpu().tolist()\n",
    "        scores = output.cpu().tolist()\n",
    "        users = info[:,0].tolist()\n",
    "        items = info[:,1].tolist()\n",
    "\n",
    "        user_list += users\n",
    "        item_list += items\n",
    "        score_list += scores\n",
    "\n",
    "np_user_list = np.array(user_list)\n",
    "np_item_list = np.array(item_list)\n",
    "np_score_list = np.array(score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 10 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31360/31360 [25:27<00:00, 20.53it/s]\n"
     ]
    }
   ],
   "source": [
    "users = list()\n",
    "items = list()\n",
    "for user_code, u_id in tqdm(user_dict.items()):\n",
    "    u_id = int(u_id)\n",
    "\n",
    "    idx = np.where(np_user_list == user_code)[0].tolist()\n",
    "    \n",
    "    item_score = np_score_list.take(idx) #user code 에 해당하는 item_score\n",
    "    item_ = np_item_list.take(idx) # user code에 해당하는 item\n",
    "    top10_idx = np.argpartition(item_score, -10)[-10:] # 상위 10개 index 추출\n",
    "\n",
    "    top10_item = [int(item_dict[code]) for code in item_.take(top10_idx)] #top 10(item code -> item id)\n",
    "    user_id = [u_id] * 10\n",
    "\n",
    "    users += user_id\n",
    "    items += top10_item\n",
    "\n",
    "result = np.vstack((users,items)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### submission 생성\n",
    "- submission 경로 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = pd.DataFrame(result, columns=['user','item'])\n",
    "info.to_csv(\"./output/FFM3_submission_2epoch.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall@10 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing recall@10...\n",
      "Number of users : 31360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31360/31360 [00:26<00:00, 1166.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted submission result of Recall@10 = 0.15552359693877554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "print(\"testing recall@10...\")\n",
    "# 학습에 사용된 user만 uniq_user에 저장\n",
    "uniq_user = list(user_dict.values())\n",
    "print (f\"Number of users : {len(uniq_user)}\")\n",
    "\n",
    "with open(\"/opt/ml/input/workspace/BERT4Rec/data/answers.json\", \"r\") as json_file: #answer.json 경로 지정\n",
    "    answer = json.load(json_file)\n",
    "\n",
    "# movielens-20m과 submission을 비교하여 Recall@10 값 계산\n",
    "submission_df = info\n",
    "#submission_df = pd.read_csv(\"/opt/ml/input/output/submission_deepFM.csv\")\n",
    "recall_result = []\n",
    "\n",
    "# 각 유저마다 recall@10 계산하여 list에 저장\n",
    "for user in tqdm(uniq_user):\n",
    "    submission_by_user = submission_df[submission_df['user'] == user]['item']\n",
    "    user = int(user)\n",
    "    hit = 0\n",
    "    for item in submission_by_user:\n",
    "        if item in answer[str(user)]:\n",
    "            hit += 1\n",
    "\n",
    "        recall_result.append(hit / 10)\n",
    "\n",
    "# 전체 유저의 Recall@10의 평균 출력\n",
    "print (f\"Predicted submission result of Recall@10 = {np.average(recall_result)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
